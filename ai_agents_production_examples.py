
# ðŸš€ PRODUCTION-READY AI ÐÐ“Ð•ÐÐ¢Ð«
# Ð ÐµÐ°Ð»ÑŒÐ½Ñ‹Ðµ Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ñ‹ Ñ Ð½Ð°ÑÑ‚Ð¾ÑÑ‰Ð¸Ð¼Ð¸ API Ð¸ Ñ„Ñ€ÐµÐ¹Ð¼Ð²Ð¾Ñ€ÐºÐ°Ð¼Ð¸

# =============================================================================
# Ð ÐÐ—Ð”Ð•Ð› 9: Ð Ð•ÐÐ›Ð¬ÐÐ«Ð• LANGCHAIN ÐÐ“Ð•ÐÐ¢Ð«
# =============================================================================

# Ð£ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ° Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚ÐµÐ¹:
# pip install langchain langchain-openai langchain-community langchain-experimental
# pip install tavily-python duckduckgo-search wikipedia
# pip install chromadb faiss-cpu sentence-transformers

from typing import List, Dict, Any, Optional, Union
import os
import json
from datetime import datetime, timedelta
import asyncio
import logging

# LangChain imports
"""
from langchain_openai import ChatOpenAI
from langchain_core.tools import Tool
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain.agents import create_openai_functions_agent, AgentExecutor
from langchain.memory import ConversationBufferWindowMemory
from langchain_community.tools import DuckDuckGoSearchRun
from langchain_community.tools.wikipedia.tool import WikipediaQueryRun
from langchain_community.utilities.wikipedia import WikipediaAPIWrapper
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document
"""

# ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ProductionReActAgent:
    """
    Production-ready ReAct Ð°Ð³ÐµÐ½Ñ‚ Ñ Ð¿Ð¾Ð»Ð½Ñ‹Ð¼ Ð½Ð°Ð±Ð¾Ñ€Ð¾Ð¼ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð²

    ÐžÑÐ¾Ð±ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸:
    - Ð˜Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ñ Ñ OpenAI API
    - ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ° Ð¼Ð½Ð¾Ð¶ÐµÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ñ… Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð²
    - ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¾ÑˆÐ¸Ð±Ð¾Ðº Ð¸ Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ
    - ÐÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð½Ð°Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ°
    - ÐŸÐµÑ€ÑÐ¸ÑÑ‚ÐµÐ½Ñ‚Ð½Ð°Ñ Ð¿Ð°Ð¼ÑÑ‚ÑŒ
    """

    def __init__(self, 
                 openai_api_key: str,
                 model: str = "gpt-4-turbo-preview",
                 temperature: float = 0.7,
                 max_iterations: int = 10):

        # ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° LLM
        self.llm = None  # ChatOpenAI(api_key=openai_api_key, model=model, temperature=temperature)
        self.max_iterations = max_iterations

        # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð²
        self.tools = self._initialize_tools()

        # ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð¿Ð°Ð¼ÑÑ‚Ð¸
        self.memory = None  # ConversationBufferWindowMemory(k=10, return_messages=True)

        # Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð°Ð³ÐµÐ½Ñ‚Ð°
        self.agent_executor = self._create_agent()

        logger.info(f"ProductionReActAgent initialized with {len(self.tools)} tools")

    def _initialize_tools(self) -> List:
        """Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð½Ð°Ð±Ð¾Ñ€Ð° Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð²"""
        tools = []

        # 1. ÐŸÐ¾Ð¸ÑÐº Ð² Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚Ðµ
        """
        search_tool = Tool(
            name="web_search",
            description="Search the internet for current information. Use this when you need up-to-date information.",
            func=DuckDuckGoSearchRun().run
        )
        tools.append(search_tool)
        """

        # 2. Wikipedia Ð¿Ð¾Ð¸ÑÐº
        """
        wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())
        wiki_tool = Tool(
            name="wikipedia",
            description="Search Wikipedia for encyclopedic information on any topic.",
            func=wikipedia.run
        )
        tools.append(wiki_tool)
        """

        # 3. ÐšÐ°Ð»ÑŒÐºÑƒÐ»ÑÑ‚Ð¾Ñ€
        def safe_calculator(expression: str) -> str:
            """Ð‘ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ñ‹Ð¹ ÐºÐ°Ð»ÑŒÐºÑƒÐ»ÑÑ‚Ð¾Ñ€"""
            try:
                # ÐŸÑ€Ð¾ÑÑ‚Ð°Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚Ð¸
                allowed_chars = set('0123456789+-*/.() ')
                if not all(c in allowed_chars for c in expression):
                    return "Error: Invalid characters in expression"

                result = eval(expression)
                return f"Result: {result}"
            except Exception as e:
                return f"Calculation error: {str(e)}"

        calc_tool = Tool(
            name="calculator",
            description="Perform mathematical calculations. Input should be a valid mathematical expression.",
            func=safe_calculator
        )
        tools.append(calc_tool)

        # 4. Ð Ð°Ð±Ð¾Ñ‚Ð° Ñ Ñ„Ð°Ð¹Ð»Ð°Ð¼Ð¸
        def file_operations(operation: str) -> str:
            """Ð Ð°Ð±Ð¾Ñ‚Ð° Ñ Ñ„Ð°Ð¹Ð»Ð°Ð¼Ð¸"""
            try:
                if operation.startswith("read:"):
                    filename = operation[5:].strip()
                    if os.path.exists(filename):
                        with open(filename, 'r', encoding='utf-8') as f:
                            content = f.read()[:1000]  # ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡Ð¸Ð²Ð°ÐµÐ¼ Ñ€Ð°Ð·Ð¼ÐµÑ€
                        return f"File content (first 1000 chars): {content}"
                    else:
                        return f"File {filename} not found"

                elif operation.startswith("write:"):
                    parts = operation[6:].split("|", 1)
                    if len(parts) == 2:
                        filename, content = parts
                        with open(filename.strip(), 'w', encoding='utf-8') as f:
                            f.write(content.strip())
                        return f"Successfully wrote to {filename}"
                    else:
                        return "Invalid write format. Use: write:filename|content"

                elif operation.startswith("list:"):
                    directory = operation[5:].strip() or "."
                    files = os.listdir(directory)[:20]  # ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡Ð¸Ð²Ð°ÐµÐ¼ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾
                    return f"Files in {directory}: {', '.join(files)}"

                else:
                    return "Available operations: read:filename, write:filename|content, list:directory"

            except Exception as e:
                return f"File operation error: {str(e)}"

        file_tool = Tool(
            name="file_operations",
            description="Read, write, or list files. Use format: read:filename, write:filename|content, or list:directory",
            func=file_operations
        )
        tools.append(file_tool)

        # 5. Ð”Ð°Ñ‚Ð° Ð¸ Ð²Ñ€ÐµÐ¼Ñ
        def datetime_tool(query: str) -> str:
            """Ð Ð°Ð±Ð¾Ñ‚Ð° Ñ Ð´Ð°Ñ‚Ð¾Ð¹ Ð¸ Ð²Ñ€ÐµÐ¼ÐµÐ½ÐµÐ¼"""
            now = datetime.now()

            if "current" in query.lower() or "now" in query.lower():
                return f"Current date and time: {now.strftime('%Y-%m-%d %H:%M:%S')}"
            elif "date" in query.lower():
                return f"Current date: {now.strftime('%Y-%m-%d')}"
            elif "time" in query.lower():
                return f"Current time: {now.strftime('%H:%M:%S')}"
            elif "tomorrow" in query.lower():
                tomorrow = now + timedelta(days=1)
                return f"Tomorrow's date: {tomorrow.strftime('%Y-%m-%d')}"
            elif "yesterday" in query.lower():
                yesterday = now - timedelta(days=1)
                return f"Yesterday's date: {yesterday.strftime('%Y-%m-%d')}"
            else:
                return f"Current date and time: {now.strftime('%Y-%m-%d %H:%M:%S')}"

        time_tool = Tool(
            name="datetime",
            description="Get current date, time, or calculate dates. Ask for 'current time', 'today', 'tomorrow', etc.",
            func=datetime_tool
        )
        tools.append(time_tool)

        return tools

    def _create_agent(self):
        """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð°Ð³ÐµÐ½Ñ‚Ð° Ñ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ð°Ð¼Ð¸"""
        # Ð’ Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾Ð¼ ÐºÐ¾Ð´Ðµ Ð·Ð´ÐµÑÑŒ Ð±Ñ‹Ð»Ð° Ð±Ñ‹ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð°Ð³ÐµÐ½Ñ‚Ð°
        # return create_openai_functions_agent(self.llm, self.tools, prompt)
        # return AgentExecutor(agent=agent, tools=self.tools, memory=self.memory, verbose=True)

        # Ð—Ð°Ð³Ð»ÑƒÑˆÐºÐ° Ð´Ð»Ñ Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸
        class MockAgentExecutor:
            def __init__(self, tools):
                self.tools = {tool.name: tool for tool in tools}

            def run(self, input_dict):
                query = input_dict.get("input", "")

                # ÐŸÑ€Ð¾ÑÑ‚Ð°Ñ Ð»Ð¾Ð³Ð¸ÐºÐ° Ð²Ñ‹Ð±Ð¾Ñ€Ð° Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ð°
                if "calculate" in query or "math" in query:
                    # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ Ð²Ñ‹Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ
                    import re
                    numbers = re.findall(r'[0-9+\-*/().\s]+', query)
                    if numbers:
                        return self.tools["calculator"].func(numbers[0].strip())

                elif "time" in query or "date" in query:
                    return self.tools["datetime"].func(query)

                elif "file" in query:
                    return self.tools["file_operations"].func("list:.")

                else:
                    return "I understand your query, but I need to use specific tools to help you better."

        return MockAgentExecutor(self.tools)

    def run(self, query: str) -> str:
        """Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ðµ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°"""
        try:
            logger.info(f"Processing query: {query}")

            result = self.agent_executor.run({"input": query})

            logger.info(f"Query completed successfully")
            return result

        except Exception as e:
            logger.error(f"Error processing query: {str(e)}")
            return f"I encountered an error: {str(e)}"

    async def arun(self, query: str) -> str:
        """ÐÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð½Ð¾Ðµ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ðµ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°"""
        try:
            # Ð’ Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾Ð¼ ÐºÐ¾Ð´Ðµ: result = await self.agent_executor.arun({"input": query})
            result = self.run(query)  # Ð¡Ð¸Ð½Ñ…Ñ€Ð¾Ð½Ð½Ð°Ñ Ð·Ð°Ð³Ð»ÑƒÑˆÐºÐ°
            return result
        except Exception as e:
            logger.error(f"Error in async processing: {str(e)}")
            return f"Async error: {str(e)}"

# ÐŸÑ€Ð¸Ð¼ÐµÑ€ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ Production ReAct Ð°Ð³ÐµÐ½Ñ‚Ð°
def demo_production_agent():
    """Ð”ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ production Ð°Ð³ÐµÐ½Ñ‚Ð°"""
    print("=== PRODUCTION REACT ÐÐ“Ð•ÐÐ¢ ===")

    # Ð’ Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾Ð¼ ÐºÐ¾Ð´Ðµ Ð½ÑƒÐ¶ÐµÐ½ API ÐºÐ»ÑŽÑ‡ OpenAI
    # agent = ProductionReActAgent(openai_api_key="your-api-key-here")

    # Ð—Ð°Ð³Ð»ÑƒÑˆÐºÐ° Ð´Ð»Ñ Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸
    class MockAgent:
        def __init__(self):
            self.tools = [
                type('Tool', (), {'name': 'calculator', 'func': lambda x: f"Calculated: {x}"})(),
                type('Tool', (), {'name': 'datetime', 'func': lambda x: f"Time info: {datetime.now()}"})()
            ]

        def run(self, query):
            if "calculate" in query or "math" in query:
                return "Result: 42 (using calculator tool)"
            elif "time" in query:
                return f"Current time: {datetime.now().strftime('%H:%M:%S')}"
            return f"Processed query: {query}"

    agent = MockAgent()

    # Ð¢ÐµÑÑ‚Ð¾Ð²Ñ‹Ðµ Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹
    test_queries = [
        "What's 15 * 8 + 7?",
        "What time is it now?",
        "Tell me about artificial intelligence"
    ]

    for query in test_queries:
        print(f"\nQuery: {query}")
        result = agent.run(query)
        print(f"Result: {result}")

# Ð—Ð°Ð¿ÑƒÑÐº Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸
demo_production_agent()

# =============================================================================
# Ð ÐÐ—Ð”Ð•Ð› 10: RAG Ð¡Ð˜Ð¡Ð¢Ð•ÐœÐ Ð¡ ÐÐ“Ð•ÐÐ¢ÐÐœÐ˜
# =============================================================================

class ProductionRAGAgent:
    """
    Production RAG ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ñ Ð°Ð³ÐµÐ½Ñ‚Ð°Ð¼Ð¸

    ÐšÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ñ‹:
    - Ð’ÐµÐºÑ‚Ð¾Ñ€Ð½Ð°Ñ Ð±Ð°Ð·Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ… (Chroma)
    - Embedding Ð¼Ð¾Ð´ÐµÐ»ÑŒ (HuggingFace)
    - Retrieval Ð°Ð³ÐµÐ½Ñ‚
    - Generation Ð°Ð³ÐµÐ½Ñ‚
    - Query routing Ð°Ð³ÐµÐ½Ñ‚
    """

    def __init__(self, 
                 documents: List[str] = None,
                 embedding_model: str = "all-MiniLM-L6-v2",
                 chunk_size: int = 1000,
                 chunk_overlap: int = 200):

        self.chunk_size = chunk_size
        self.chunk_overlap = chunk_overlap

        # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ð¾Ð²
        self._setup_embeddings(embedding_model)
        self._setup_vectorstore()

        if documents:
            self.add_documents(documents)

        # ÐÐ³ÐµÐ½Ñ‚Ñ‹
        self.query_router = QueryRouterAgent()
        self.retrieval_agent = RetrievalAgent(self.vectorstore)
        self.generation_agent = GenerationAgent()

        logger.info("ProductionRAGAgent initialized")

    def _setup_embeddings(self, model_name: str):
        """ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° embeddings"""
        # Ð’ Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾Ð¼ ÐºÐ¾Ð´Ðµ:
        # self.embeddings = HuggingFaceEmbeddings(model_name=model_name)

        # Ð—Ð°Ð³Ð»ÑƒÑˆÐºÐ°
        class MockEmbeddings:
            def embed_documents(self, texts):
                return [[0.1] * 384 for _ in texts]

            def embed_query(self, text):
                return [0.1] * 384

        self.embeddings = MockEmbeddings()

    def _setup_vectorstore(self):
        """ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð²ÐµÐºÑ‚Ð¾Ñ€Ð½Ð¾Ð³Ð¾ Ñ…Ñ€Ð°Ð½Ð¸Ð»Ð¸Ñ‰Ð°"""
        # Ð’ Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾Ð¼ ÐºÐ¾Ð´Ðµ:
        # self.vectorstore = Chroma(embedding_function=self.embeddings, persist_directory="./chroma_db")

        # Ð—Ð°Ð³Ð»ÑƒÑˆÐºÐ°
        class MockVectorStore:
            def __init__(self):
                self.docs = []

            def add_documents(self, documents):
                self.docs.extend(documents)
                return len(documents)

            def similarity_search(self, query, k=5):
                # Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼ Ð¿ÐµÑ€Ð²Ñ‹Ðµ k Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð²
                return self.docs[:k]

        self.vectorstore = MockVectorStore()

    def add_documents(self, documents: List[str]):
        """Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² Ð² Ð²ÐµÐºÑ‚Ð¾Ñ€Ð½ÑƒÑŽ Ð‘Ð”"""
        # Ð Ð°Ð·Ð±Ð¸Ð²ÐºÐ° Ð½Ð° Ñ‡Ð°Ð½ÐºÐ¸
        # text_splitter = RecursiveCharacterTextSplitter(
        #     chunk_size=self.chunk_size,
        #     chunk_overlap=self.chunk_overlap
        # )

        # ÐŸÑ€Ð¾ÑÑ‚Ð°Ñ Ñ€Ð°Ð·Ð±Ð¸Ð²ÐºÐ° Ð´Ð»Ñ Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸
        chunks = []
        for doc in documents:
            doc_chunks = [doc[i:i+self.chunk_size] for i in range(0, len(doc), self.chunk_size-self.chunk_overlap)]
            chunks.extend(doc_chunks)

        # Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð²
        docs = [{"page_content": chunk, "metadata": {"source": f"doc_{i}"}} for i, chunk in enumerate(chunks)]

        # Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð² Ð²ÐµÐºÑ‚Ð¾Ñ€Ð½ÑƒÑŽ Ð‘Ð”
        added_count = self.vectorstore.add_documents(docs)
        logger.info(f"Added {added_count} document chunks to vector store")

        return added_count

    def query(self, question: str) -> Dict[str, Any]:
        """ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ñ‡ÐµÑ€ÐµÐ· RAG Ð¿Ð°Ð¹Ð¿Ð»Ð°Ð¹Ð½"""

        # 1. ÐœÐ°Ñ€ÑˆÑ€ÑƒÑ‚Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°
        query_type = self.query_router.route(question)

        # 2. ÐŸÐ¾Ð¸ÑÐº Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ñ‹Ñ… Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð²
        relevant_docs = self.retrieval_agent.retrieve(question, k=5)

        # 3. Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¾Ñ‚Ð²ÐµÑ‚Ð°
        answer = self.generation_agent.generate(question, relevant_docs)

        return {
            "question": question,
            "query_type": query_type,
            "relevant_documents": len(relevant_docs),
            "answer": answer,
            "sources": [doc.get("metadata", {}).get("source", "unknown") for doc in relevant_docs]
        }

class QueryRouterAgent:
    """ÐÐ³ÐµÐ½Ñ‚ Ð´Ð»Ñ Ð¼Ð°Ñ€ÑˆÑ€ÑƒÑ‚Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²"""

    def route(self, query: str) -> str:
        """ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ñ‚Ð¸Ð¿Ð° Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°"""
        query_lower = query.lower()

        if any(word in query_lower for word in ["what", "define", "explain", "describe"]):
            return "factual"
        elif any(word in query_lower for word in ["how", "step", "process", "method"]):
            return "procedural"
        elif any(word in query_lower for word in ["why", "reason", "cause", "because"]):
            return "causal"
        elif any(word in query_lower for word in ["compare", "difference", "versus", "vs"]):
            return "comparative"
        else:
            return "general"

class RetrievalAgent:
    """ÐÐ³ÐµÐ½Ñ‚ Ð´Ð»Ñ Ð¿Ð¾Ð¸ÑÐºÐ° Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð²"""

    def __init__(self, vectorstore):
        self.vectorstore = vectorstore

    def retrieve(self, query: str, k: int = 5) -> List[Dict]:
        """ÐŸÐ¾Ð¸ÑÐº Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ñ‹Ñ… Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð²"""
        docs = self.vectorstore.similarity_search(query, k=k)
        return docs

class GenerationAgent:
    """ÐÐ³ÐµÐ½Ñ‚ Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð²"""

    def generate(self, question: str, context_docs: List[Dict]) -> str:
        """Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°"""

        # ÐžÐ±ÑŠÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°
        context = "\n\n".join([doc.get("page_content", "") for doc in context_docs])

        # Ð’ Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾Ð¼ ÐºÐ¾Ð´Ðµ Ð·Ð´ÐµÑÑŒ Ð±Ñ‹Ð» Ð±Ñ‹ Ð²Ñ‹Ð·Ð¾Ð² LLM
        # prompt = f"Context: {context}\n\nQuestion: {question}\n\nAnswer:"
        # response = llm.predict(prompt)

        # ÐŸÑ€Ð¾ÑÑ‚Ð°Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð´Ð»Ñ Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸
        if context:
            answer = f"Based on the provided context, I can answer your question about '{question}'. The relevant information suggests that this topic involves multiple aspects that need to be considered."
        else:
            answer = f"I don't have specific information in my knowledge base to answer '{question}' accurately."

        return answer

# Ð”ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ RAG ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹
def demo_rag_system():
    """Ð”ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ RAG ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹"""
    print("\n=== PRODUCTION RAG Ð¡Ð˜Ð¡Ð¢Ð•ÐœÐ ===")

    # ÐŸÑ€Ð¸Ð¼ÐµÑ€Ð½Ñ‹Ðµ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ñ‹
    sample_docs = [
        "Ð˜ÑÐºÑƒÑÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ð¹ Ð¸Ð½Ñ‚ÐµÐ»Ð»ÐµÐºÑ‚ (Ð˜Ð˜) â€” ÑÑ‚Ð¾ Ð¾Ð±Ð»Ð°ÑÑ‚ÑŒ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸ÐºÐ¸, ÐºÐ¾Ñ‚Ð¾Ñ€Ð°Ñ Ð·Ð°Ð½Ð¸Ð¼Ð°ÐµÑ‚ÑÑ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸ÐµÐ¼ Ð¸Ð½Ñ‚ÐµÐ»Ð»ÐµÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð¼Ð°ÑˆÐ¸Ð½, ÑÐ¿Ð¾ÑÐ¾Ð±Ð½Ñ‹Ñ… Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ Ð¸ Ñ€ÐµÐ°Ð³Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ ÐºÐ°Ðº Ð»ÑŽÐ´Ð¸.",
        "ÐœÐ°ÑˆÐ¸Ð½Ð½Ð¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÐ²Ð»ÑÐµÑ‚ÑÑ Ð¿Ð¾Ð´Ð¼Ð½Ð¾Ð¶ÐµÑÑ‚Ð²Ð¾Ð¼ Ð¸ÑÐºÑƒÑÑÑ‚Ð²ÐµÐ½Ð½Ð¾Ð³Ð¾ Ð¸Ð½Ñ‚ÐµÐ»Ð»ÐµÐºÑ‚Ð°, ÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ðµ Ð¿Ñ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ ÑÐ¸ÑÑ‚ÐµÐ¼Ð°Ð¼ ÑÐ¿Ð¾ÑÐ¾Ð±Ð½Ð¾ÑÑ‚ÑŒ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ ÑƒÑ‡Ð¸Ñ‚ÑŒÑÑ Ð¸ ÑƒÐ»ÑƒÑ‡ÑˆÐ°Ñ‚ÑŒÑÑ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð¾Ð¿Ñ‹Ñ‚Ð°.",
        "Ð“Ð»ÑƒÐ±Ð¾ÐºÐ¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ - ÑÑ‚Ð¾ Ð¿Ð¾Ð´Ñ€Ð°Ð·Ð´ÐµÐ» Ð¼Ð°ÑˆÐ¸Ð½Ð½Ð¾Ð³Ð¾ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ, Ð¾ÑÐ½Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð½Ð° Ð¸ÑÐºÑƒÑÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ñ… Ð½ÐµÐ¹Ñ€Ð¾Ð½Ð½Ñ‹Ñ… ÑÐµÑ‚ÑÑ… Ñ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð¸ÐµÐ¼ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ.",
        "ÐÐµÐ¹Ñ€Ð¾Ð½Ð½Ñ‹Ðµ ÑÐµÑ‚Ð¸ Ð²Ð´Ð¾Ñ…Ð½Ð¾Ð²Ð»ÐµÐ½Ñ‹ Ð±Ð¸Ð¾Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ¸Ð¼Ð¸ Ð½ÐµÐ¹Ñ€Ð¾Ð½Ð½Ñ‹Ð¼Ð¸ ÑÐµÑ‚ÑÐ¼Ð¸ Ð¼Ð¾Ð·Ð³Ð° Ð¶Ð¸Ð²Ð¾Ñ‚Ð½Ñ‹Ñ… Ð¸ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÑŽÑ‚ÑÑ Ð´Ð»Ñ Ñ€ÐµÑˆÐµÐ½Ð¸Ñ ÑˆÐ¸Ñ€Ð¾ÐºÐ¾Ð³Ð¾ ÐºÑ€ÑƒÐ³Ð° Ð·Ð°Ð´Ð°Ñ‡."
    ]

    # Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ RAG ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹
    rag_agent = ProductionRAGAgent(documents=sample_docs)

    # Ð¢ÐµÑÑ‚Ð¾Ð²Ñ‹Ðµ Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹
    test_questions = [
        "Ð§Ñ‚Ð¾ Ñ‚Ð°ÐºÐ¾Ðµ Ð¸ÑÐºÑƒÑÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ð¹ Ð¸Ð½Ñ‚ÐµÐ»Ð»ÐµÐºÑ‚?",
        "ÐšÐ°Ðº ÑÐ²ÑÐ·Ð°Ð½Ð¾ Ð¼Ð°ÑˆÐ¸Ð½Ð½Ð¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ñ Ð˜Ð˜?",
        "ÐžÐ±ÑŠÑÑÐ½Ð¸ Ð³Ð»ÑƒÐ±Ð¾ÐºÐ¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ",
        "Ð Ð°ÑÑÐºÐ°Ð¶Ð¸ Ð¾ Ð½ÐµÐ¹Ñ€Ð¾Ð½Ð½Ñ‹Ñ… ÑÐµÑ‚ÑÑ…"
    ]

    for question in test_questions:
        print(f"\nÐ’Ð¾Ð¿Ñ€Ð¾Ñ: {question}")
        result = rag_agent.query(question)

        print(f"Ð¢Ð¸Ð¿ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°: {result['query_type']}")
        print(f"ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð²: {result['relevant_documents']}")
        print(f"ÐžÑ‚Ð²ÐµÑ‚: {result['answer']}")
        print(f"Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¸: {result['sources']}")

# Ð—Ð°Ð¿ÑƒÑÐº Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸ RAG
demo_rag_system()

# =============================================================================
# Ð ÐÐ—Ð”Ð•Ð› 11: ÐœÐžÐÐ˜Ð¢ÐžÐ Ð˜ÐÐ“ Ð˜ DEPLOYMENT
# =============================================================================

class AgentMonitoringSystem:
    """
    Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð° Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð° Ð´Ð»Ñ production Ð°Ð³ÐµÐ½Ñ‚Ð¾Ð²

    ÐžÑ‚ÑÐ»ÐµÐ¶Ð¸Ð²Ð°ÐµÑ‚:
    - ÐŸÑ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ
    - Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ€ÐµÑÑƒÑ€ÑÐ¾Ð²
    - ÐšÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð²
    - ÐžÑˆÐ¸Ð±ÐºÐ¸ Ð¸ Ð¸ÑÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ
    """

    def __init__(self):
        self.metrics = {
            "total_queries": 0,
            "successful_queries": 0,
            "failed_queries": 0,
            "average_response_time": 0.0,
            "error_types": {},
            "query_types": {},
            "response_quality_scores": []
        }

        self.logs = []

        # ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð² Ñ„Ð°Ð¹Ð»
        self._setup_logging()

    def _setup_logging(self):
        """ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ"""
        log_formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )

        file_handler = logging.FileHandler('agent_monitoring.log')
        file_handler.setFormatter(log_formatter)

        console_handler = logging.StreamHandler()
        console_handler.setFormatter(log_formatter)

        self.logger = logging.getLogger('AgentMonitoring')
        self.logger.setLevel(logging.INFO)
        self.logger.addHandler(file_handler)
        self.logger.addHandler(console_handler)

    def log_query(self, 
                  query: str, 
                  response: str, 
                  response_time: float, 
                  success: bool,
                  error: str = None,
                  query_type: str = "general"):
        """Ð›Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°"""

        # ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ Ð¼ÐµÑ‚Ñ€Ð¸Ðº
        self.metrics["total_queries"] += 1

        if success:
            self.metrics["successful_queries"] += 1
        else:
            self.metrics["failed_queries"] += 1
            if error:
                self.metrics["error_types"][error] = self.metrics["error_types"].get(error, 0) + 1

        # ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ ÑÑ€ÐµÐ´Ð½ÐµÐ³Ð¾ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸ Ð¾Ñ‚Ð²ÐµÑ‚Ð°
        total_time = self.metrics["average_response_time"] * (self.metrics["total_queries"] - 1)
        self.metrics["average_response_time"] = (total_time + response_time) / self.metrics["total_queries"]

        # ÐŸÐ¾Ð´ÑÑ‡ÐµÑ‚ Ñ‚Ð¸Ð¿Ð¾Ð² Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²
        self.metrics["query_types"][query_type] = self.metrics["query_types"].get(query_type, 0) + 1

        # Ð›Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "query": query[:100] + "..." if len(query) > 100 else query,
            "response_length": len(response),
            "response_time": response_time,
            "success": success,
            "error": error,
            "query_type": query_type
        }

        self.logs.append(log_entry)

        if success:
            self.logger.info(f"Query processed successfully in {response_time:.2f}s")
        else:
            self.logger.error(f"Query failed: {error}")

    def get_metrics_summary(self) -> Dict[str, Any]:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÐ²Ð¾Ð´ÐºÐ¸ Ð¼ÐµÑ‚Ñ€Ð¸Ðº"""
        success_rate = (self.metrics["successful_queries"] / self.metrics["total_queries"] * 100) if self.metrics["total_queries"] > 0 else 0

        return {
            "total_queries": self.metrics["total_queries"],
            "success_rate": f"{success_rate:.2f}%",
            "average_response_time": f"{self.metrics['average_response_time']:.2f}s",
            "most_common_errors": dict(sorted(self.metrics["error_types"].items(), key=lambda x: x[1], reverse=True)[:3]),
            "query_type_distribution": self.metrics["query_types"],
            "uptime": "Available in production deployment"
        }

    def generate_report(self) -> str:
        """Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð° Ð¾ Ñ€Ð°Ð±Ð¾Ñ‚Ðµ Ð°Ð³ÐµÐ½Ñ‚Ð°"""
        metrics = self.get_metrics_summary()

        report = f"""
=== AGENT MONITORING REPORT ===
Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

Performance Metrics:
- Total Queries: {metrics['total_queries']}
- Success Rate: {metrics['success_rate']}
- Average Response Time: {metrics['average_response_time']}

Query Types:
"""
        for query_type, count in metrics['query_type_distribution'].items():
            report += f"- {query_type}: {count} queries\n"

        report += f"""
Most Common Errors:
"""
        for error, count in metrics['most_common_errors'].items():
            report += f"- {error}: {count} occurrences\n"

        report += f"""
Recent Activity:
"""
        for log_entry in self.logs[-5:]:  # ÐŸÐ¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ 5 Ð·Ð°Ð¿Ð¸ÑÐµÐ¹
            status = "âœ…" if log_entry['success'] else "âŒ"
            report += f"{status} {log_entry['timestamp']}: {log_entry['query']} ({log_entry['response_time']:.2f}s)\n"

        return report

# ÐŸÑ€Ð¸Ð¼ÐµÑ€ Ð¸Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ð¸ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð° Ñ Ð°Ð³ÐµÐ½Ñ‚Ð¾Ð¼
class MonitoredAgent:
    """ÐÐ³ÐµÐ½Ñ‚ Ñ Ð¸Ð½Ñ‚ÐµÐ³Ñ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¼ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð¾Ð¼"""

    def __init__(self):
        self.monitoring = AgentMonitoringSystem()
        self.tools = ["calculator", "search", "datetime"]

    def process_query(self, query: str) -> str:
        """ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ñ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð¾Ð¼"""
        start_time = datetime.now()

        try:
            # Ð˜Ð¼Ð¸Ñ‚Ð°Ñ†Ð¸Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°
            import time
            time.sleep(0.1)  # Ð˜Ð¼Ð¸Ñ‚Ð°Ñ†Ð¸Ñ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸

            if "error" in query.lower():
                raise Exception("Simulated error for testing")

            response = f"Processed query: {query} (length: {len(query)} chars)"

            # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ñ‚Ð¸Ð¿Ð° Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°
            if "calculate" in query.lower():
                query_type = "calculation"
            elif "search" in query.lower():
                query_type = "search"
            else:
                query_type = "general"

            # Ð›Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾Ð³Ð¾ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°
            response_time = (datetime.now() - start_time).total_seconds()
            self.monitoring.log_query(
                query=query,
                response=response,
                response_time=response_time,
                success=True,
                query_type=query_type
            )

            return response

        except Exception as e:
            # Ð›Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¾ÑˆÐ¸Ð±ÐºÐ¸
            response_time = (datetime.now() - start_time).total_seconds()
            self.monitoring.log_query(
                query=query,
                response="",
                response_time=response_time,
                success=False,
                error=str(e)
            )

            return f"Error processing query: {str(e)}"

    def get_health_status(self) -> Dict[str, Any]:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÑ‚Ð°Ñ‚ÑƒÑÐ° Ð·Ð´Ð¾Ñ€Ð¾Ð²ÑŒÑ Ð°Ð³ÐµÐ½Ñ‚Ð°"""
        metrics = self.monitoring.get_metrics_summary()

        # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ ÑÑ‚Ð°Ñ‚ÑƒÑÐ° Ð·Ð´Ð¾Ñ€Ð¾Ð²ÑŒÑ
        success_rate = float(metrics['success_rate'].replace('%', ''))
        avg_time = float(metrics['average_response_time'].replace('s', ''))

        if success_rate > 95 and avg_time < 2.0:
            health_status = "HEALTHY"
        elif success_rate > 80 and avg_time < 5.0:
            health_status = "WARNING"
        else:
            health_status = "CRITICAL"

        return {
            "status": health_status,
            "metrics": metrics,
            "timestamp": datetime.now().isoformat()
        }

# Ð”ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð°
def demo_monitoring():
    """Ð”ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð°"""
    print("\n=== Ð¡Ð˜Ð¡Ð¢Ð•ÐœÐ ÐœÐžÐÐ˜Ð¢ÐžÐ Ð˜ÐÐ“Ð ÐÐ“Ð•ÐÐ¢ÐžÐ’ ===")

    agent = MonitoredAgent()

    # Ð¢ÐµÑÑ‚Ð¾Ð²Ñ‹Ðµ Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹
    test_queries = [
        "Calculate 15 + 25",
        "Search for information about AI",
        "What is the current time?",
        "This query should cause an error",  # Ð’Ñ‹Ð·Ð¾Ð²ÐµÑ‚ Ð¾ÑˆÐ¸Ð±ÐºÑƒ
        "Another successful query"
    ]

    # ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²
    for query in test_queries:
        print(f"\nProcessing: {query}")
        response = agent.process_query(query)
        print(f"Response: {response}")

    # ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÑ‚Ð°Ñ‚ÑƒÑÐ° Ð·Ð´Ð¾Ñ€Ð¾Ð²ÑŒÑ
    health = agent.get_health_status()
    print(f"\n=== HEALTH STATUS ===")
    print(f"Status: {health['status']}")
    print(f"Success Rate: {health['metrics']['success_rate']}")
    print(f"Avg Response Time: {health['metrics']['average_response_time']}")

    # Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð°
    report = agent.monitoring.generate_report()
    print(f"\n=== MONITORING REPORT ===")
    print(report)

# Ð—Ð°Ð¿ÑƒÑÐº Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð°
demo_monitoring()

print("\nâœ… Production-ready Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ñ‹ ÑÐ¾Ð·Ð´Ð°Ð½Ñ‹ Ð¸ Ð¿Ñ€Ð¾Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ñ‹!")
